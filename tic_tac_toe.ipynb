{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "import numpy as np\n",
    "from copy import deepcopy\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.animation import ArtistAnimation\n",
    "import random\n",
    "import functools\n",
    "\n",
    "# For debugging purposes\n",
    "from IPython.core.debugger import set_trace\n",
    "\n",
    "plt.rcParams[\"animation.html\"] = \"jshtml\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class InvalidMove(Exception):\n",
    "    \"\"\"\n",
    "    Exception class indicating invalid moves\n",
    "\n",
    "    Raised if an agent tries to move in a way not according to the rules e.g.:\n",
    "\n",
    "    returns None\n",
    "    returns an already occupied cell\n",
    "    returns a cell outside of the playing field\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, agent, board, move):\n",
    "        \"\"\"\n",
    "        Constructor\n",
    "\n",
    "        params:\n",
    "            - culprit: the agent causing the exception\n",
    "            - state: the current board state without the executed move\n",
    "            - move: the move causing the exception\n",
    "        \"\"\"\n",
    "        self.culprit = agent\n",
    "        self.state = board\n",
    "        self.move = move\n",
    "\n",
    "    def __repr__(self):\n",
    "        \"\"\"\n",
    "        Wrapper for __str__\n",
    "        \"\"\"\n",
    "        return str(self)\n",
    "\n",
    "    def __str__(self):\n",
    "        \"\"\"\n",
    "        Conversion to string representation\n",
    "        \"\"\"\n",
    "        return \"Illegal Move: %s wants to do %s\" % (self.culprit, self.move)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Board:\n",
    "    \"\"\"\n",
    "    Representation of the game state\n",
    "    \"\"\"\n",
    "    WON = 1\n",
    "    LOST = 2\n",
    "    DRAW = 3\n",
    "    READY = 0\n",
    "    ONGOING = 4\n",
    "\n",
    "    def __init__(self, size, agent_ids):\n",
    "        \"\"\"\n",
    "        Constructor\n",
    "\n",
    "        params:\n",
    "            - size: Size of the field (single dimension)\n",
    "            - agentIDs: IDs of the agents playing the game\n",
    "        \"\"\"\n",
    "        self.agent_ids = agent_ids\n",
    "        self.field = np.zeros((size, size), dtype=np.intp)\n",
    "        self.lastMove = None\n",
    "        self.size = size\n",
    "\n",
    "        # Construction of line templates used for counting lines\n",
    "        x_template = np.array([(i, 0) for i in range(5)], dtype=np.intp)\n",
    "        y_template = np.array([(0, i) for i in range(5)], dtype=np.intp)\n",
    "        x_lines = [x_template + (0, i) for i in range(5)]\n",
    "        y_lines = [y_template + (i, 0) for i in range(5)]\n",
    "        cross_lines = [np.array([np.zeros(2, dtype=np.intp) + i for i in range(5)]),\n",
    "                       np.array([np.array([0, 4], dtype=np.intp) + (i, -i) for i in range(5)])]\n",
    "        self.lines = []\n",
    "        self.lines.extend(cross_lines)\n",
    "        self.lines.extend(x_lines)\n",
    "        self.lines.extend(y_lines)\n",
    "\n",
    "    def execute(self, move):\n",
    "        \"\"\"\n",
    "        Execute a move on the board\n",
    "\n",
    "        params:\n",
    "            - move: 2 tuple containing agentID and move\n",
    "        returns:\n",
    "            - Reference to the modified board\n",
    "        \"\"\"\n",
    "        if self.field[move[1][0], move[1][1]] == 0:\n",
    "            self.field[move[1][0], move[1][1]] = move[0]\n",
    "        else:\n",
    "            raise InvalidMove(move[0], self, move[1])\n",
    "        self.lastMove = move[1]\n",
    "        return self\n",
    "\n",
    "    def __do_it(self, agent_id):\n",
    "        \"\"\"\n",
    "        Helper function to count lines\n",
    "\n",
    "        params:\n",
    "            - agentId: ID of the agent lines should be counted for\n",
    "        returns:\n",
    "            - list of number of lines in descending order of line length\n",
    "        \"\"\"\n",
    "        line_length = {0: 0, 1: 0, 2: 0, 3: 0, 4: 0, 5: 0}\n",
    "        for line in self.lines:\n",
    "            length = 0\n",
    "            for cell in line:\n",
    "                if self.field[cell[0], cell[1]] == agent_id:\n",
    "                    length += 1\n",
    "                    continue\n",
    "                if not self.field[cell[0], cell[1]] == 0:\n",
    "                    length = 0\n",
    "                    break\n",
    "            line_length[length] += 1\n",
    "        length_list = np.zeros(self.size)\n",
    "        for i in range(self.size):\n",
    "            length_list[i] = line_length[self.size - i]\n",
    "        return length_list\n",
    "\n",
    "    def get_lines(self, agent):\n",
    "        \"\"\"\n",
    "        Extracts the current feature vector from the board\n",
    "\n",
    "        params:\n",
    "            - agent: the agent defining the perspective of the features\n",
    "        returns:\n",
    "            - numpy array containing the number of lines of the agents in descending order of length\n",
    "              concatenated with the number of lines of the oponnent agent multiplied by -1\n",
    "        \"\"\"\n",
    "        agent_list = self.__do_it(agent.i)\n",
    "        other_id = [i for i in self.agent_ids if i != agent.i][0]\n",
    "        other_list = self.__do_it(other_id)\n",
    "        return np.concatenate([agent_list, -1 * other_list])\n",
    "\n",
    "    def get_free_list(self):\n",
    "        \"\"\"\n",
    "        Returns the list of still possible moves\n",
    "\n",
    "        returns:\n",
    "            - List of moves possible on the current board\n",
    "        \"\"\"\n",
    "        return np.array(np.where(self.field == 0), dtype=np.intp).T\n",
    "\n",
    "    def is_finished(self):\n",
    "        \"\"\"\n",
    "        Checks if game has ended\n",
    "\n",
    "        returns:\n",
    "            - True if game ended, False otherwise\n",
    "        \"\"\"\n",
    "        if len(self.get_free_list()) == 0:\n",
    "            return True\n",
    "        if self.__do_it(self.agent_ids[0])[0]:\n",
    "            return True\n",
    "        if self.__do_it(self.agent_ids[1])[0]:\n",
    "            return True\n",
    "        return False\n",
    "\n",
    "    def get_game_state(self, agent):\n",
    "        \"\"\"\n",
    "        Returns the current game state\n",
    "\n",
    "        returns:\n",
    "            - Board.WON, Board.LOST, Board.DRAW if game ended,\n",
    "            Board.READY if game not yet started, Board.ONGOING otherwise\n",
    "        \"\"\"\n",
    "        if self.is_finished():\n",
    "            if self.__do_it(agent.i)[0]:\n",
    "                return Board.WON\n",
    "            if not len(self.get_free_list()):\n",
    "                return Board.DRAW\n",
    "            return Board.LOST\n",
    "        if len(self.get_free_list()) == self.size ** 2:\n",
    "            return Board.READY\n",
    "        return Board.ONGOING\n",
    "\n",
    "    def render(self, ax):\n",
    "        \"\"\"\n",
    "        Renders the board to an image\n",
    "\n",
    "        To be called by Game.render! Not for direct use!\n",
    "\n",
    "        params:\n",
    "            - ax: a matplotlib axis object\n",
    "        returns:\n",
    "            - a list of drawn patches\n",
    "        \"\"\"\n",
    "        output = []\n",
    "\n",
    "        for line in np.transpose(np.where(self.field == self.agent_ids[0])):\n",
    "            output.append(Board.token(ax, line, \"red\"))\n",
    "\n",
    "        for line in np.transpose(np.where(self.field == self.agent_ids[1])):\n",
    "            output.append(Board.token(ax, line, \"blue\"))\n",
    "\n",
    "        return output\n",
    "\n",
    "    @staticmethod\n",
    "    def token(ax, pos, color):\n",
    "        \"\"\"\n",
    "        Renders a token to the board image\n",
    "\n",
    "        params:\n",
    "            - ax: a matplotlib axis object\n",
    "            - pos: the position to render\n",
    "            - color: the color of the token\n",
    "        returns:\n",
    "            - the patch created by the token\n",
    "        \"\"\"\n",
    "        patch = plt.Circle(pos + (0.5, 0.5), radius=0.4, color=color)\n",
    "        ax.add_patch(patch)\n",
    "        return patch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Game:\n",
    "    \"\"\"\n",
    "    Tic-Tac-Toe Game Representation\n",
    "\n",
    "    The class handles the game logic and runs the games.\n",
    "    It also allows for visualization of a games result using the render method.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, size, agent0, agent1):\n",
    "        \"\"\"\n",
    "        Constructor\n",
    "\n",
    "        params:\n",
    "            - size: Size of the board (one dimension)\n",
    "            - agent0: Reference to the first agent\n",
    "            - agent1: Reference to the second agent\n",
    "        \"\"\"\n",
    "        self.board = Board(size, (agent0.i, agent1.i))\n",
    "        self.agents = (agent0, agent1)\n",
    "\n",
    "    def run(self):\n",
    "        \"\"\"\n",
    "        Run the game with supplied agents\n",
    "\n",
    "        returns:\n",
    "            - Tuple containing result, boards and agents\n",
    "            - result: One of Board.WON, Board.LOST, Board.DRAW\n",
    "            - boards: List of intermediate Board states during the game\n",
    "            - agents: List of references to the playing agents\n",
    "        \"\"\"\n",
    "        boards = []\n",
    "        while not self.board.is_finished():\n",
    "            for agent in self.agents:\n",
    "                move = agent.next_move(deepcopy(self.board))\n",
    "                try:\n",
    "                    self.board.execute(move)\n",
    "                except InvalidMove:\n",
    "                    print(\"Invalid move: %s wants to %s\" % (agent, move[1]))\n",
    "                    return Board.WON if agent.i == self.agents[1].i else Board.LOST, boards\n",
    "                boards.append(deepcopy(self.board))\n",
    "                if self.board.is_finished():\n",
    "                    break\n",
    "        return self.board.get_game_state(self.agents[0]), boards, self.agents\n",
    "\n",
    "    def render(self, boards):\n",
    "        \"\"\"\n",
    "        Render multiple board states into a single video\n",
    "\n",
    "        Params:\n",
    "            boards: numpy array containing board states\n",
    "\n",
    "        Returns:\n",
    "            An animation object of matplotlib\n",
    "        \"\"\"\n",
    "        fig, ax = plt.subplots()\n",
    "\n",
    "        x = self.board.field.shape[0]\n",
    "        y = self.board.field.shape[1]\n",
    "\n",
    "        ax.set_xlim(0, x)\n",
    "        ax.set_ylim(0, y)\n",
    "\n",
    "        ax.set_xticklabels([])\n",
    "        ax.set_xticks(np.arange(1, x - 0.5))\n",
    "        ax.set_yticklabels([])\n",
    "        ax.set_yticks(np.arange(1, y - 0.5))\n",
    "        ax.vlines(range(0, x), 0, y, \"grey\")\n",
    "        ax.hlines(range(0, y), 0, x, \"grey\")\n",
    "\n",
    "        images = []\n",
    "        images = functools.reduce(lambda images, b: images + [b.render(ax)], boards, [])\n",
    "\n",
    "        ArtistAnimation(fig, images, interval=1000)\n",
    "        plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Agent:\n",
    "    \"\"\"\n",
    "    Generic Agent\n",
    "\n",
    "    Base Class\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, i):\n",
    "        \"\"\"\n",
    "        Constructor:\n",
    "\n",
    "        params:\n",
    "            - i: ID of the agent (needs to be unique)\n",
    "        \"\"\"\n",
    "        self.i = i\n",
    "\n",
    "    def __repr__(self):\n",
    "        \"\"\"\n",
    "        Wrapper for __str__\n",
    "        \"\"\"\n",
    "        return str(self)\n",
    "\n",
    "    def __str__(self):\n",
    "        \"\"\"\n",
    "        Convert Agent to string using class name and ID\n",
    "        \"\"\"\n",
    "        return \"%s %i\" % (self.__class__.__name__, self.i)\n",
    "\n",
    "\n",
    "class RandomAgent(Agent):\n",
    "    \"\"\"\n",
    "    Random Tic-Tac-Toe Agent\n",
    "\n",
    "    Plays a random move from the list of still allowed moves\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, i):\n",
    "        \"\"\"\n",
    "        Constructor\n",
    "\n",
    "        params:\n",
    "            - i: Agent ID\n",
    "        \"\"\"\n",
    "        super().__init__(i)\n",
    "\n",
    "    def next_move(self, board):\n",
    "        \"\"\"\n",
    "        Compute next move\n",
    "\n",
    "        selects a move from the boards free list randomly\n",
    "\n",
    "        params:\n",
    "            - board: current board state\n",
    "\n",
    "        returns:\n",
    "            - the selected move\n",
    "        \"\"\"\n",
    "        moves = board.get_free_list()\n",
    "        move = moves[np.random.randint(0, len(moves))]\n",
    "        return self.i, move\n",
    "\n",
    "\n",
    "class GoodAgent(Agent):\n",
    "    \"\"\"\n",
    "    Good Tic-Tac-Toe Agent\n",
    "\n",
    "    Tries to enhance its own lines according to length and blocks opponents lines\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, i):\n",
    "        \"\"\"\n",
    "        Constructor\n",
    "\n",
    "        params:\n",
    "            - i: Agent ID\n",
    "            - size: size of the board\n",
    "        \"\"\"\n",
    "        super().__init__(i)\n",
    "        # Magical weight vector containing the agents logic\n",
    "        self.w = np.array([100, 8, 4, 2, 1, 32, 16, 8, 4, 2])\n",
    "\n",
    "    def evaluate(self, board):\n",
    "        \"\"\"\n",
    "        Evaluate a boards quality, see V-function\n",
    "\n",
    "        params:\n",
    "            - board: the current board state\n",
    "\n",
    "        returns:\n",
    "            A scalar number representing the board quality\n",
    "        \"\"\"\n",
    "        return np.dot(self.w, board.get_lines(self))\n",
    "\n",
    "    def next_move(self, board):\n",
    "        \"\"\"\n",
    "        Compute next move\n",
    "\n",
    "        selects the best move based on the resulting boards quality as provided by the evaluate function\n",
    "\n",
    "        params:\n",
    "            - board: current board state\n",
    "\n",
    "        returns:\n",
    "            - the selected move\n",
    "        \"\"\"\n",
    "        # bestMoveValue = None\n",
    "        # bestMove = None\n",
    "        moves = board.get_free_list()\n",
    "        boards = [deepcopy(board).execute((self.i, move)) for move in moves]\n",
    "        values = [self.evaluate(board) for board in boards]\n",
    "        i = np.argmax(values)\n",
    "        return self.i, moves[i]\n",
    "\n",
    "\n",
    "class GreedyAgent(GoodAgent):\n",
    "    \"\"\"\n",
    "    Greedy Tic-Tac-Toe Agent\n",
    "\n",
    "    Tries to extend its own lines without caring for the opponent\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, i):\n",
    "        \"\"\"\n",
    "        Constructor\n",
    "\n",
    "        params:\n",
    "            - i: Agent ID\n",
    "            - size: Size of the board\n",
    "        \"\"\"\n",
    "        super().__init__(i)\n",
    "        # Magical weight vector containing the agents logic\n",
    "        self.w = np.array([10000, 1000, 100, 10, 1, 0, 0, 0, 0, 0])\n",
    "\n",
    "\n",
    "class LearningAgent(GoodAgent):\n",
    "    \"\"\"\n",
    "    Adaptive Tic-Tac-Toe Agent\n",
    "\n",
    "    Learn a strategy based on the features provided by the board\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, i, eta):\n",
    "        \"\"\"\n",
    "        Constructor\n",
    "\n",
    "        params:\n",
    "            - i: Agent ID\n",
    "            - size: size of the board\n",
    "        \"\"\"\n",
    "        super().__init__(i)\n",
    "        self.eta = eta\n",
    "        self.w = np.zeros(2 * 5)\n",
    "\n",
    "    def learn(self, boards):\n",
    "        \"\"\"\n",
    "        Learn the weight vector based on the boards observed in a game\n",
    "\n",
    "        TODO: to be implemented by the student\n",
    "\n",
    "        params:\n",
    "            - boards: list of boards observed in a game\n",
    "        returns:\n",
    "            - learning error\n",
    "        \"\"\"\n",
    "        return 0\n",
    "\n",
    "    def __str__(self):\n",
    "        \"\"\"\n",
    "        Convert Agent to string using weights and ID\n",
    "        \"\"\"\n",
    "        weights = \"\"\n",
    "        for w in self.w:\n",
    "            weights += f'{w:.2f}, '\n",
    "        return f\"Learning Agent(eta: {self.eta}) ID: {self.i}: {weights[:-2]}\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compete(agent1, agent2, n):\n",
    "    \"\"\"\n",
    "    Competition between two agents without learning\n",
    "\n",
    "    params:\n",
    "        - agent1: reference to first agent\n",
    "        - agent2: reference to second agent\n",
    "        - n: number of games\n",
    "    returns:\n",
    "        - Directory with result counts (Boards.DRAW, Boards.WON, Boards.LOST)\n",
    "    \"\"\"\n",
    "    results = {Board.DRAW: 0, Board.WON: 0, Board.LOST: 0}\n",
    "    for i in range(n):\n",
    "        result, boards, agents = Game(5, agent1, agent2).run()\n",
    "        results[result] += 1\n",
    "    print(f\"Results:\\n\\tWon: {results[Board.WON]}\\n\\tLost: {results[Board.LOST]}\\n\\tDraw: {results[Board.DRAW]}\")\n",
    "    return results\n",
    "\n",
    "\n",
    "def train(agent1, agent2, n):\n",
    "    \"\"\"\n",
    "    Competition between two agents with learning\n",
    "\n",
    "    params:\n",
    "        - agent1: reference to first agent\n",
    "        - agent2: reference to second agent\n",
    "        - n: number of games\n",
    "    returns:\n",
    "        - Directory with result counts (Boards.DRAW, Boards.WON, Boards.LOST)\n",
    "    \"\"\"\n",
    "    agents = [agent1, agent2]\n",
    "    old_r = None\n",
    "    d_r = None\n",
    "    l_agents = [i for i in range(len(agents)) if isinstance(agents[i], LearningAgent)]\n",
    "    e = []\n",
    "    results = []\n",
    "    while True:\n",
    "        e.append(np.zeros(len(l_agents)))\n",
    "        results.append({Board.DRAW: 0, Board.WON: 0, Board.LOST: 0})\n",
    "        for i in range(n):\n",
    "            result, boards, agents = Game(5, agent1, agent2).run()\n",
    "            for j in l_agents:\n",
    "                e[-1][j] = agents[j].learn(boards)\n",
    "            results[-1][result] += 1\n",
    "        for i in l_agents:\n",
    "            print(f\"{agents[i]} - Error: {e[-1][i]:.2f}\")\n",
    "        print(f\"Results: Won: {results[-1][Board.WON]} Lost: {results[-1][Board.LOST]} Draw: {results[-1][Board.DRAW]}\")\n",
    "        if (e[-1] == 0).any():\n",
    "            break\n",
    "        if len(e) >= 2:\n",
    "            if (np.abs(e[-2] - e[-1]) < 1).any():\n",
    "                break\n",
    "            d_r = 0\n",
    "            for key in results[-2]:\n",
    "                d_r += abs(results[-2][key] - results[-1][key])\n",
    "            if d_r <= 1:\n",
    "                break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "good, greed = GoodAgent(3), GreedyAgent(4)\n",
    "game = Game(5, good, greed)\n",
    "result, boards, agents = game.run()\n",
    "game.render(boards)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AgentSmith = LearningAgent(1,0.1)\n",
    "AgentSmith2 = LearningAgent(2,0.5)\n",
    "print(AgentSmith)\n",
    "print(AgentSmith2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
